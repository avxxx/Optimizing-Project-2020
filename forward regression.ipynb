{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "import scipy.linalg as sla\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from IPython.core.display import display, HTML\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix $A \\in \\mathbb{R}^{n\\times m}$, n -- number of samples, m -- number of features\\\\\n",
    "\n",
    "Vector $y\\in \\mathbb{R}^n$\n",
    "\n",
    "We suppose thar $A$ and $y$ are normalized to 1\n",
    "\n",
    "Covariance matrix $C \\in \\mathbb{R}^{d\\times d}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "m = 20\n",
    "A = np.random.rand(m, n)\n",
    "y = np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function below returns a covariance matrix for columns x_1, x_2,... of matrix X \n",
    "# normalized to have expectation 0 and variation 1\n",
    "def get_covariance_matrix(X):\n",
    "    cov_matrix = np.cov(X, bias=True)\n",
    "    return cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns normalized vector of covariances between y and columns x_1, x_2,...of matrix X \n",
    "# \n",
    "def get_covariance_vector(X, y):\n",
    "    return np.cov(np.vstack((X_T, y)))[-1,:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred, *, sample_weight=None,\n",
    "             multioutput=\"uniform_average\"):\n",
    "    \"\"\"R^2 (coefficient of determination) regression score function.\n",
    "    Best possible score is 1.0 and it can be negative (because the\n",
    "    model can be arbitrarily worse). A constant model that always\n",
    "    predicts the expected value of y, disregarding the input features,\n",
    "    would get a R^2 score of 0.0.\n",
    "    Read more in the :ref:`User Guide <r2_score>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "        Ground truth (correct) target values.\n",
    "    y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
    "        Estimated target values.\n",
    "    sample_weight : array-like of shape (n_samples,), optional\n",
    "        Sample weights.\n",
    "    multioutput : string in ['raw_values', 'uniform_average', \\\n",
    "'variance_weighted'] or None or array-like of shape (n_outputs)\n",
    "        Defines aggregating of multiple output scores.\n",
    "        Array-like value defines weights used to average scores.\n",
    "        Default is \"uniform_average\".\n",
    "        'raw_values' :\n",
    "            Returns a full set of scores in case of multioutput input.\n",
    "        'uniform_average' :\n",
    "            Scores of all outputs are averaged with uniform weight.\n",
    "        'variance_weighted' :\n",
    "            Scores of all outputs are averaged, weighted by the variances\n",
    "            of each individual output.\n",
    "        .. versionchanged:: 0.19\n",
    "            Default value of multioutput is 'uniform_average'.\n",
    "    Returns\n",
    "    -------\n",
    "    z : float or ndarray of floats\n",
    "        The R^2 score or ndarray of scores if 'multioutput' is\n",
    "        'raw_values'.\n",
    "    Notes\n",
    "    -----\n",
    "    This is not a symmetric function.\n",
    "    Unlike most other scores, R^2 score may be negative (it need not actually\n",
    "    be the square of a quantity R).\n",
    "    This metric is not well-defined for single samples and will return a NaN\n",
    "    value if n_samples is less than two.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] `Wikipedia entry on the Coefficient of determination\n",
    "            <https://en.wikipedia.org/wiki/Coefficient_of_determination>`_\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sklearn.metrics import r2_score\n",
    "    >>> y_true = [3, -0.5, 2, 7]\n",
    "    >>> y_pred = [2.5, 0.0, 2, 8]\n",
    "    >>> r2_score(y_true, y_pred)\n",
    "    0.948...\n",
    "    >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "    >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
    "    >>> r2_score(y_true, y_pred,\n",
    "    ...          multioutput='variance_weighted')\n",
    "    0.938...\n",
    "    >>> y_true = [1, 2, 3]\n",
    "    >>> y_pred = [1, 2, 3]\n",
    "    >>> r2_score(y_true, y_pred)\n",
    "    1.0\n",
    "    >>> y_true = [1, 2, 3]\n",
    "    >>> y_pred = [2, 2, 2]\n",
    "    >>> r2_score(y_true, y_pred)\n",
    "    0.0\n",
    "    >>> y_true = [1, 2, 3]\n",
    "    >>> y_pred = [3, 2, 1]\n",
    "    >>> r2_score(y_true, y_pred)\n",
    "    -3.0\n",
    "    \"\"\"\n",
    "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
    "        y_true, y_pred, multioutput)\n",
    "    check_consistent_length(y_true, y_pred, sample_weight)\n",
    "\n",
    "    if _num_samples(y_pred) < 2:\n",
    "        msg = \"R^2 score is not well-defined with less than two samples.\"\n",
    "        warnings.warn(msg, UndefinedMetricWarning)\n",
    "        return float('nan')\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        sample_weight = column_or_1d(sample_weight)\n",
    "        weight = sample_weight[:, np.newaxis]\n",
    "    else:\n",
    "        weight = 1.\n",
    "\n",
    "    numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0,\n",
    "                                                      dtype=np.float64)\n",
    "    denominator = (weight * (y_true - np.average(\n",
    "        y_true, axis=0, weights=sample_weight)) ** 2).sum(axis=0,\n",
    "                                                          dtype=np.float64)\n",
    "    nonzero_denominator = denominator != 0\n",
    "    nonzero_numerator = numerator != 0\n",
    "    valid_score = nonzero_denominator & nonzero_numerator\n",
    "    output_scores = np.ones([y_true.shape[1]])\n",
    "    output_scores[valid_score] = 1 - (numerator[valid_score] /\n",
    "                                      denominator[valid_score])\n",
    "    # arbitrary set to zero to avoid -inf scores, having a constant\n",
    "    # y_true is not interesting for scoring a regression anyway\n",
    "    output_scores[nonzero_numerator & ~nonzero_denominator] = 0.\n",
    "    if isinstance(multioutput, str):\n",
    "        if multioutput == 'raw_values':\n",
    "            # return scores individually\n",
    "            return output_scores\n",
    "        elif multioutput == 'uniform_average':\n",
    "            # passing None as weights results is uniform mean\n",
    "            avg_weights = None\n",
    "        elif multioutput == 'variance_weighted':\n",
    "            avg_weights = denominator\n",
    "            # avoid fail on constant y or one-element arrays\n",
    "            if not np.any(nonzero_denominator):\n",
    "                if not np.any(nonzero_numerator):\n",
    "                    return 1.0\n",
    "                else:\n",
    "                    return 0.0\n",
    "    else:\n",
    "        avg_weights = multioutput\n",
    "\n",
    "    return np.average(output_scores, weights=avg_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n"
     ]
    }
   ],
   "source": [
    "C = get_covariance_matrix(A)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "b = get_covariance_vector(A, y)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019258634477752175\n"
     ]
    }
   ],
   "source": [
    "# R-squared coefficient\n",
    "# \n",
    "R = np.dot(b.T, np.dot(LA.inv(C), b))\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
